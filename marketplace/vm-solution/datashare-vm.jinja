{% import "path_utils.jinja" as path_utils with context %}

imports:
- path: cloud_function.py
- path: deploy_ds_api.py
- path: deploy_ui_cloud_run.py
- path: cluster.py

{% set adminEmail = properties["input_adminEmail"] %}
{% set project = env["project"] %}
{% set datashareGitReleaseVersion = properties["input_datashareGithubReleaseVersion"] %}
{% set gcpRegion = properties["input_gcpRegion"] %}
{% set storageBucketLocation = properties["input_storageBucketLocation"] %}
{% set useRuntimeConfigWaiter = properties["input_useRuntimeConfigWaiter"] %}
{% set deployApiToGke = properties["input_deployApiToGke"] %}
{% set gkeZone = properties["input_gkeZone"] %}
{% set gkeClusterName = "datashare" %}
{% set waiterName = env["deployment"] + "-startup-waiter" %}
{% set configName = env["deployment"] + "-startup-config" %}

{% set deployment = env["deployment"] %}
{% set name = "%s-vm-tmpl" % env["name"] %}
{% set instanceName = "%s-vm" % deployment %}
{% set zone = properties["zone"] %}
{% set machineType = properties["machineType"] %}
{% set networks = [] %}
{% for network in properties["network"] %}
{% set _ = networks.append(path_utils.networkPath(network)) %}
{% endfor %}
{% set subnetworks = properties["subnetwork"] %}
{% set externalIPs = properties["externalIP"] %}
{% set bootDiskType = properties["bootDiskType"] %}
{% set bootDiskSizeGb = properties["bootDiskSizeGb"] %}
{% set hasExternalIP = externalIPs and externalIPs[0] != "NONE" %}
{# Software status only works if the VM has an external IP. #}
{% set enableStatusWaiter = hasExternalIP %}
{% set canIpForward = properties["ipForward"] == "On" %}

{% set imageProjects = ["debian-cloud"] %}
{% set imageNames = ["debian-9-stretch-v20200618"] %}
{% set selectedImageIndex = properties["image"]|int %}

resources:
  - type: storage.v1.bucket
    name: {{ project }}-cds-bucket
    properties:
      name: {{ project }}-cds-bucket
      project: {{ project }}
      #predefinedAcl: projectPrivate
      #projection: full
      location: {{ storageBucketLocation }}
      storageClass: STANDARD

  - name: datashare-cluster-manager
    type: cluster.py
    properties:
      zone: us-central1-a
      
  {% if useRuntimeConfigWaiter %}  
  - type: storage.v1.bucket
    name: {{ project }}-install-bucket
    properties:
      name: {{ project }}-install-bucket
      project: {{ project }}
      #predefinedAcl: projectPrivate
      #projection: full
      location: {{ storageBucketLocation }}
      storageClass: STANDARD
  {% endif %}

  ## Deploy the Ingestion Cloud Function
  - name: function
    type: cloud_function.py
    properties:
      # All the files that start with this prefix will be packed in the Cloud Function
      codeLocation: function/
      codeBucket: {{ project }}-install-bucket
      ## codeBucket: fsi-cds-markeplace-sw-dev-datashare-cloud-function
      codeBucketObject: datashare-toolkit-cloud-function.zip
      location: {{ gcpRegion }}
      timeout: 60s
      runtime: nodejs10
      availableMemoryMb: 256
      entryPoint: processEvent
      useRuntimeConfigWaiter: {{ useRuntimeConfigWaiter }}
      waiterName: {{ waiterName }}
      #temp: $(ref.{{ name }}.selfLink)

  ## Deploy Datashare API
  - name: build-api
    type: deploy_ds_api.py
    properties:
      serviceAccountName: ds-api-mgr
      serviceAccountDesc: DS API Manager
      customRoleName: custom.ds.api.mgr
      cloudRunDeployName: ds-api
      containerTag: dev
      region: {{ gcpRegion }}
      timeout: 600s
      datashareGitReleaseTag: {{ datashareGitReleaseVersion }}
      useRuntimeConfigWaiter: {{ useRuntimeConfigWaiter }}
      waiterName: {{ waiterName }}
      deployToGke: {{ deployApiToGke }}
      gkeZone: {{ gkeZone }}
    
  ## Deploy Datashare UI
  - name: build-ui
    type: deploy_ui_cloud_run.py
    properties:
      firebaseApiKey: YOUR_FIREBASE_WEB_APIKEY
      containerTag: dev
      region: {{ gcpRegion }}
      timeout: 600s
      datashareGitReleaseTag: {{ datashareGitReleaseVersion }}
      useRuntimeConfigWaiter: {{ useRuntimeConfigWaiter }}
      waiterName: {{ waiterName }}
  
  ## Deploy the VM instance
  - name: {{ name }}
    type: vm_instance.py
    properties:
      instanceName: {{ instanceName }}
      useRuntimeConfigWaiter: {{ useRuntimeConfigWaiter }}
      waiterConfigName: {{ configName }}
      sourceImage: https://www.googleapis.com/compute/v1/projects/{{ imageProjects[selectedImageIndex] }}/global/images/{{ imageNames[selectedImageIndex] }}
      zone: {{ zone }}
      machineType: {{ machineType }}
      networks:
      {% for network in networks %}
        - {{ network }}
      {% endfor %}
      {% if subnetworks is defined and subnetworks %}
      subnetworks:
      {% for subnetwork in subnetworks %}
        - {{ subnetwork or '' }}
      {% endfor %}
      {% endif %}
      {% if externalIPs is defined and externalIPs %}
      externalIPs:
      {% for externalIP in externalIPs %}
        - {{ externalIP }}
      {% endfor %}
      {% endif %}
      bootDiskType: {{ bootDiskType }}
      bootDiskSizeGb: {{ bootDiskSizeGb }}
      
      canIpForward: {{ canIpForward }}
      serviceAccounts:
        - email: default
          scopes:
            - 'https://www.googleapis.com/auth/cloud.useraccounts.readonly'
            - 'https://www.googleapis.com/auth/devstorage.read_only'
            - 'https://www.googleapis.com/auth/logging.write'
            - 'https://www.googleapis.com/auth/monitoring.write'
            - 'https://www.googleapis.com/auth/cloud-platform'
            - 'https://www.googleapis.com/auth/cloudruntimeconfig'

      metadata:
        items:
          - key: adminEmail
            value: {{ adminEmail }}
          - key: datashareGitReleaseVersion
            value: {{ datashareGitReleaseVersion }}
          {% if deployApiToGke %}   
          - key: gkeZone
            value: {{ gkeZone }}
          - key: deployApiToGke
            value: {{ deployApiToGke }}
          - key: gkeClusterName
            value: {{ gkeClusterName }}
          {% endif %}  
          {% if useRuntimeConfigWaiter %}  
          - key: useRuntimeConfigWaiter
            value: {{ useRuntimeConfigWaiter }}
          - key: configName
            value: {{ configName }}
          {% endif %}
          - key: startup-script
            value: |-
              #!/bin/bash

              # use curl and metadata url to access adminEmail
              #ADMIN_EMAIL=`curl http://metadata.google.internal/computeMetadata/v1/instance/attributes/adminEmail -H "Metadata-Flavor: Google"`
              #echo $ADMIN_EMAIL
              CLOUD_FUNCTION_ZIP_FILE_NAME="datashare-toolkit-cloud-function.zip"
              USE_RUNTIME_CONFIG_WAITER=`curl http://metadata.google.internal/computeMetadata/v1/instance/attributes/useRuntimeConfigWaiter -H "Metadata-Flavor: Google"`
              echo $USE_RUNTIME_CONFIG_WAITER
              VM_STARTUP_SCRIPT=true

              if [ "$USE_RUNTIME_CONFIG_WAITER" = "true" ]; then
                echo "Using Runtime Config Waiter to install Datashare prerequisites..."
                IS_GIT_INSTALLED=`dpkg-query -W -f='${Status}\n' git`
                if [ "$IS_GIT_INSTALLED" != "install ok installed" ]; then
                    echo "Installing git."
                    sudo apt-get install git -y
                fi
                IS_ZIP_INSTALLED=`dpkg-query -W -f='${Status}\n' zip`
                if [ "$IS_ZIP_INSTALLED" != "install ok installed" ]; then
                    echo "Installing zip."
                    sudo apt-get install zip -y
                fi
                IS_KUBECTL_INSTALLED=`dpkg-query -W -f='${Status}\n' kubectl`
                if [ "$IS_KUBECTL_INSTALLED" != "install ok installed" ]; then
                    echo "Installing kubectl."
                    sudo apt-get install kubectl -y
                fi

                cd /opt
                echo "Cloning the Datashare repository..."
                git clone https://github.com/GoogleCloudPlatform/datashare-toolkit.git
                
                # checkout the Datashare release version specified in the Deployment package description
                cd datashare-toolkit
                DATASHARE_GIT_RELEASE_VERSION=`curl http://metadata.google.internal/computeMetadata/v1/instance/attributes/datashareGitReleaseVersion -H "Metadata-Flavor: Google"`
                echo $DATASHARE_GIT_RELEASE_VERSION
                if [ "$DATASHARE_GIT_RELEASE_VERSION" != "master" ]; then
                    echo "Using Datashare release version $DATASHARE_GIT_RELEASE_VERSION"
                    git checkout -b $DATASHARE_GIT_RELEASE_VERSION # this should be changed to external metadata
                fi
                
                cd ..
                FUNCTION_SHARED="./datashare-toolkit/ingestion/batch/shared"
                if [ -d "${FUNCTION_SHARED}" ]; then
                    rm -R "${FUNCTION_SHARED}"
                fi

                echo "Copying shared module into function directory..."
                sudo cp -R datashare-toolkit/shared/ "${FUNCTION_SHARED}/"

                # linux
                echo 'Running on linux, performing package.json replacement for cds-shared module'
                sed -i -E 's/(file:)(\.\.\/\.\.\/)(shared)/\1\3/g' ./datashare-toolkit/ingestion/batch/package.json

                # Zip the Cloud Function package
                cd /opt/datashare-toolkit/ingestion/batch
                zip -r $CLOUD_FUNCTION_ZIP_FILE_NAME * .eslintrc.json configurationManager.js index.js package.js package-lock.json shared/

                #PROJECT=`curl http://metadata.google.internal/computeMetadata/v1/project/project-id -H "Metadata-Flavor: Google"`
                export PROJECT_ID=$(gcloud config list --format 'value(core.project)')

                # Enable APIs
                echo "Enabling Cloud APIs"
                gcloud services enable cloudbuild.googleapis.com --quiet
                gcloud services enable cloudfunctions.googleapis.com --quiet
                gcloud services enable iam.googleapis.com --quiet
                gcloud services enable run.googleapis.com --quiet
                gcloud services enable cloudresourcemanager.googleapis.com --quiet
                # Enabling APIs for GKE cluster
                gcloud services enable container.googleapis.com containerregistry.googleapis.com --quiet

                # Upload Cloud Function to Google Cloud storage
                gsutil cp $CLOUD_FUNCTION_ZIP_FILE_NAME gs://$PROJECT_ID-install-bucket/
                # TODO - we should notify a new Waiter here so that the Cloud Function deployment can start at this point instead of waiting until the end.

                # Update permission on Deployment Manager service account (cloudservices.gserviceaccount.com)
                export PROJECT_NUMBER=`gcloud projects list --filter=$(gcloud config get-value project) --format="value(PROJECT_NUMBER)"`
                echo "Adding IAM policy to Deployment Manager service account..."
                gcloud projects add-iam-policy-binding $(gcloud config get-value project) --member="serviceAccount:$PROJECT_NUMBER@cloudservices.gserviceaccount.com" --role="roles/storage.admin"
                
                # Update permissions on Cloud Build service account (@cloudbuild.gserviceaccount.com)
                echo "Adding IAM policy to Cloud Build service account..."
                echo "Adding iam.admin role to Cloud Build service account"
                gcloud projects add-iam-policy-binding $(gcloud config get-value project) --member="serviceAccount:$PROJECT_NUMBER@cloudbuild.gserviceaccount.com" --role="roles/iam.serviceAccountAdmin" 
                echo "Adding cloudrun.admin role to Cloud Build service account"
                gcloud projects add-iam-policy-binding $(gcloud config get-value project) --member="serviceAccount:$PROJECT_NUMBER@cloudbuild.gserviceaccount.com" --role="roles/run.admin"
                echo "Adding iam.roleadmin role to Cloud Build service account"
                gcloud projects add-iam-policy-binding $(gcloud config get-value project) --member="serviceAccount:$PROJECT_NUMBER@cloudbuild.gserviceaccount.com" --role="roles/iam.roleAdmin"
                echo "Adding iam.securityadmin role to Cloud Build service account"
                gcloud projects add-iam-policy-binding $(gcloud config get-value project) --member="serviceAccount:$PROJECT_NUMBER@cloudbuild.gserviceaccount.com" --role="roles/iam.securityAdmin"
                echo "Adding run.serviceagent role to Cloud Build service account"
                gcloud projects add-iam-policy-binding $(gcloud config get-value project) --member="serviceAccount:$PROJECT_NUMBER@cloudbuild.gserviceaccount.com" --role="roles/run.serviceAgent"
                
                
                echo "Updating apt-get and updating gcloud..." 
                sudo apt-get -y update && sudo apt-get -y --only-upgrade install google-cloud-sdk-skaffold kubectl google-cloud-sdk-anthos-auth google-cloud-sdk-minikube google-cloud-sdk google-cloud-sdk-app-engine-grpc google-cloud-sdk-kind google-cloud-sdk-pubsub-emulator google-cloud-sdk-app-engine-go google-cloud-sdk-firestore-emulator google-cloud-sdk-cloud-build-local google-cloud-sdk-datastore-emulator google-cloud-sdk-kpt google-cloud-sdk-app-engine-python google-cloud-sdk-spanner-emulator google-cloud-sdk-cbt google-cloud-sdk-bigtable-emulator google-cloud-sdk-app-engine-python-extras google-cloud-sdk-datalab google-cloud-sdk-app-engine-java
                sudo apt-get -y install google-cloud-sdk
                echo "Notifiying Waiter that this VM startup script is complete..."
                CONFIG_NAME=`curl http://metadata.google.internal/computeMetadata/v1/instance/attributes/configName -H "Metadata-Flavor: Google"`
                echo $CONFIG_NAME

                # Setup GKE cluster
                DEPLOY_API_TO_GKE=`curl http://metadata.google.internal/computeMetadata/v1/instance/attributes/deployApiToGke -H "Metadata-Flavor: Google"`
                if [ "$DEPLOY_API_TO_GKE" = "true" ]; then
                    echo "Adding container.clusterAdmin role to Cloud Build service account"
                    gcloud projects add-iam-policy-binding $(gcloud config get-value project) --member="serviceAccount:$PROJECT_NUMBER@cloudbuild.gserviceaccount.com" --role="roles/container.clusterAdmin"
                    gcloud projects add-iam-policy-binding $(gcloud config get-value project) --member="serviceAccount:$PROJECT_NUMBER@cloudbuild.gserviceaccount.com" --role="roles/container.viewer"
                    gcloud projects add-iam-policy-binding $(gcloud config get-value project) --member="serviceAccount:$PROJECT_NUMBER@cloudbuild.gserviceaccount.com" --role="roles/container.admin"
                    gcloud projects add-iam-policy-binding $(gcloud config get-value project) --member="serviceAccount:$PROJECT_NUMBER-compute@developer.gserviceaccount.com" --role="roles/container.admin"

                    # This is executing from the VM's startup script
                    if [ "$VM_STARTUP_SCRIPT" = true ]; then
                        export KUBECONFIG="/opt/.kube/config"
                    else
                    # This is executing from Cloud Shell
                        export KUBECONFIG="~/.kube/config"
                    fi
                    GKE_ZONE=`curl http://metadata.google.internal/computeMetadata/v1/instance/attributes/gkeZone -H "Metadata-Flavor: Google"`
                    GKE_CLUSTER_NAME=`curl http://metadata.google.internal/computeMetadata/v1/instance/attributes/gkeClusterName -H "Metadata-Flavor: Google"`
                    
                    echo "Getting the cluster credentials"
                    gcloud container clusters get-credentials $GKE_CLUSTER_NAME --zone $GKE_ZONE
                    echo "Setting up GKE cluster for Cloud Run."
                    echo "Creating the cluster role binding."
                    kubectl create clusterrolebinding cluster-admin-binding \
                        --clusterrole cluster-admin \
                        --user ${PROJECT_NUMBER}-compute@developer.gserviceaccount.com
                
                    ISTIO_PACKAGE=$(kubectl -n gke-system get deployments istio-pilot \
                        -o jsonpath="{.spec.template.spec.containers[0].image}" | \
                        cut -d':' -f2)
                    echo "Istio Package is " + $ISTIO_PACKAGE
                    ISTIO_VERSION=$(echo $ISTIO_PACKAGE | cut -d'-' -f1)
                    echo "Istio version is " + $ISTIO_VERSION

                    echo "Fetching Istio release."
                    gsutil -m cp gs://istio-release/releases/${ISTIO_VERSION}/istio-${ISTIO_VERSION}-linux.tar.gz - | tar zx
                    
                    if ! helm &> /dev/null 
                    then
                        echo "Installing Helm"
                        curl https://helm.baltorepo.com/organization/signing.asc | sudo apt-key add -
                        sudo apt-get install apt-transport-https --yes
                        echo "deb https://baltocdn.com/helm/stable/debian/ all main" | sudo tee /etc/apt/sources.list.d/helm-stable-debian.list
                        sudo apt-get update
                        sudo apt-get install helm
                        echo "Helm installed."
                    fi

                    echo "Building the Helm template"
                    /usr/sbin/helm template \
                        --namespace gke-system \
                        --set global.hub=gcr.io/gke-release/asm \
                        --set global.tag=$ISTIO_PACKAGE \
                        --set pilot.enabled=false \
                        --set security.enabled=true \
                        --set sidecarInjectorWebhook.enabled=true \
                        --set sidecarInjectorWebhook.rewriteAppHTTPProbe=true \
                        --values istio-${ISTIO_VERSION}/install/kubernetes/helm/istio/values-istio-minimal.yaml \
                        istio-${ISTIO_VERSION}/install/kubernetes/helm/istio \
                        > istio-${ISTIO_VERSION}-sidecar-injector-webhook.yaml
                    
                    echo "Installing Istio into the cluster."
                    kubectl apply -f istio-${ISTIO_VERSION}-sidecar-injector-webhook.yaml
                    echo "Checking the rollout status."
                    kubectl rollout status deploy istio-sidecar-injector -n gke-system

                    export NAMESPACE=datashare-apis
                    kubectl create namespace $NAMESPACE
                    export SERVICE_ACCOUNT_NAME=ds-api-mgr
                    export KSA_NAME=$SERVICE_ACCOUNT_NAME
                    echo "Creating Kubernets service account."
                    kubectl create serviceaccount $KSA_NAME -n $NAMESPACE;

                    echo "Binding the GCP service account to the K8S service account"
                    gcloud iam service-accounts add-iam-policy-binding \
                        --role roles/iam.workloadIdentityUser \
                        --member "serviceAccount:${PROJECT_ID}.svc.id.goog[${NAMESPACE}/${KSA_NAME}]" ${SERVICE_ACCOUNT_NAME}@${PROJECT_ID}.iam.gserviceaccount.com

                    echo "Annotating the service account."
                    kubectl annotate serviceaccount $KSA_NAME -n $NAMESPACE iam.gke.io/gcp-service-account=${SERVICE_ACCOUNT_NAME}@${PROJECT_ID}.iam.gserviceaccount.com
                    echo "Labeling the namespace."
                    kubectl label namespace $NAMESPACE istio-injection=enabled
                    echo "GKE setup complete."
                fi

                # Notify Listener
                gcloud beta runtime-config configs variables set success/my-instance success --config-name $CONFIG_NAME
                echo "VM startup-script finished!"

              else
                echo "Will not use Google Cloud Runtime Config Waiter to install prerequisites."
                echo "You must install the prerequisites before you launch this service. Execute the install-datashare-prerequisites.sh file from Cloud Shell."
                echo "The file is located in the datashare-toolkit/marketplace folder."
                echo "VM startup-script finished!"
              fi
              
      tags:
        items:
          - {{ env["deployment"] }}-deployment
  
  # Runtime Config Waiter
  {% if useRuntimeConfigWaiter %}
  - name: my-waiter
    type: waiter.jinja
    properties:
      #instanceName: cds-vm-1
      instanceName: {{ instanceName }}
  {% endif %}

  #- name: generated-password-0
  #  type: password.py
  #  properties:
  #    length: 8
  #    includeSymbols: True

  {% if properties["enableTcp80"] %}
  - name: {{ env["deployment"] }}-tcp-80
    type: compute.v1.firewall
    properties:
      network: {{ networks[0] }}
      {% if properties.get("tcp80SourceRanges") %}
      sourceRanges:
        {% for source in properties["tcp80SourceRanges"].split(',') %}
        - '{{ source | trim }}'
        {% endfor %}
      {% else %}
      sourceRanges: ["0.0.0.0/0"]
      {% endif %}
      targetTags: ["{{ env["deployment"] }}-deployment"]
      allowed:
        - IPProtocol: TCP
          ports: ["80"]
  {% endif %}

outputs:
  - name: deployment
    value: {{ deployment }}
  - name: project
    value: {{ project }}
  - name: vmId
    value: $(ref.{{ instanceName }}.id)
  - name: vmExternalIP
    {% if hasExternalIP %}
    value: $(ref.{{ name }}.ip)
    {% else %}
    value: NONE
    {% endif %}
  - name: vmInternalIP
    value: $(ref.{{ name }}.internalIP)
  - name: vmName
    value: {{ instanceName }}
  - name: vmSelfLink
    value: $(ref.{{ instanceName }}.selfLink)
  - name: hasExternalIP
    value: {{ hasExternalIP }}
  - name: mainNetwork
    value: {{ networks[0] }}
